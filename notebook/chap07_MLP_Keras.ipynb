{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOW11yDBLz2yKPeXcxUQlXX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimtaeyoon1/pdm05/blob/main/notebook/chap07_MLP_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP : Keras"
      ],
      "metadata": {
        "id": "_-DVzv996Snm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mini_batch 구현 (중요함)"
      ],
      "metadata": {
        "id": "34amnCL-6XVG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjkTgDmw6HvO",
        "outputId": "8e5af744-9e52-49e2-b7fa-2df63e4da8b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (60000,)\n",
            "[5 0 4 1 9 2 1 3 1 4]\n",
            "(10000, 28, 28) (10000,)\n",
            "[7 2 1 0 4 1 4 9 5 9]\n",
            "[47787 25412 51069 52044 50245   469 32439 23771  9035  4465 57039 12323]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12, 28, 28), (12,))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# 데이터를 학습 데이터와 테스트 데이터로 나눈다. \n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "print(x_train.shape,y_train.shape)\n",
        "print(y_train[:10])\n",
        "print(x_test.shape,y_test.shape)\n",
        "print(y_test[:10])\n",
        "\n",
        "data_size = x_train.shape[0]\n",
        "batch_size = 12\t# 배치 크기\n",
        "\n",
        "selected = np.random.choice(data_size, batch_size)\n",
        "print(selected)\n",
        "x_batch = x_train[selected]\n",
        "y_batch = y_train[selected]\n",
        "x_batch.shape, y_batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mini-batch : XOR using MLP"
      ],
      "metadata": {
        "id": "yGTUoRu07Fat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# XOR solution by MLP\n",
        "\n",
        "# 시그모이드 함수\n",
        "def actf(x):\n",
        "\treturn 1/(1+np.exp(-x))\n",
        "\n",
        "# 시그모이드 함수의 미분치\n",
        "def actf_deriv(x):\n",
        "\t    return x*(1-x)\n",
        "\n",
        "# 입력유닛의 개수, 은닉유닛의 개수, 출력유닛의 개수\n",
        "inputs, hiddens, outputs = 2, 2, 1\n",
        "learning_rate = 0.5\n",
        "\n",
        "# 훈련 입력과 출력\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "T = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# 가중치를 –1.0에서 1.0 사이의 난수로 초기화한다.\n",
        "W1 = 2*np.random.random((inputs, hiddens))-1   \n",
        "W2 = 2*np.random.random((hiddens, outputs))-1  \n",
        "B1 = np.zeros(hiddens)   \n",
        "B2 = np.zeros(outputs)   \n",
        "\n",
        "# 순방향 전파 계산\n",
        "def predict(x):\n",
        "        layer0 = x\t\t\t# 입력을 layer0에 대입한다. \n",
        "        Z1 = np.dot(layer0, W1)+B1\t# 행렬의 곱을 계산한다. \n",
        "        layer1 = actf(Z1)\t\t# 활성화 함수를 적용한다. \n",
        "        Z2 = np.dot(layer1, W2)+B2\t# 행렬의 곱을 계산한다. \n",
        "        layer2 = actf(Z2)\t\t# 활성화 함수를 적용한다. \n",
        "        return layer0, layer1, layer2\n",
        "    \n",
        "# 역방향 전파 계산\n",
        "def fit():\n",
        "    global W1, W2, B1, B2\n",
        "    for i in range(60000):\n",
        "            layer0, layer1, layer2 = predict(X) # input-batch-size = 4\n",
        "            layer2_error = layer2-T\n",
        "\n",
        "            layer2_delta = layer2_error*actf_deriv(layer2)\n",
        "            layer1_error = np.dot(layer2_delta, W2.T)\n",
        "            layer1_delta = layer1_error*actf_deriv(layer1)\n",
        "            \n",
        "            W2 += -learning_rate*np.dot(layer1.T, layer2_delta)/4.0 # 4개의 입력에 대한 평균 기울기\n",
        "            W1 += -learning_rate*np.dot(layer0.T, layer1_delta)/4.0\n",
        "            B2 += -learning_rate*np.sum(layer2_delta, axis=0)/4.0\n",
        "            B1 += -learning_rate*np.sum(layer1_delta, axis=0)/4.0\n",
        "\n",
        "def test():\n",
        "    for x, y in zip(X, T):\n",
        "        x = np.reshape(x, (1, -1))\t\t# 하나여도 2차원 형태이어야 한다.\n",
        "        layer0, layer1, layer2 = predict(x)\n",
        "        print(x, y, layer2)\n",
        "\n",
        "fit()\n",
        "test()"
      ],
      "metadata": {
        "id": "GkpF3Upx7h-2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}